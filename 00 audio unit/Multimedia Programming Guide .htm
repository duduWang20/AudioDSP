<!DOCTYPE html>
<!-- saved from url=(0119)https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Using Audio</title>
    <meta http-equiv="X-UA-Compatible" content="IE=7">
    
    <meta id="book-resource-type" name="book-resource-type" content="Guide">
    <meta scheme="apple_ref" id="identifier" name="identifier" content="//apple_ref/doc/uid/TP40009767">
    <meta id="document-version" name="document-version" content="1.4.0">
    <meta id="build" name="build" content="c1e4c7a89af8f899a21cfa81fc33ba42">
    <meta id="chapterId" name="chapterId" content="TP40009767-CH2">
    <meta id="date" name="date" content="2015-03-09">
    <meta id="description" name="description" content="Describes the usage of audio and video technologies.">
    <meta id="book-title" name="book-title" content="Multimedia Programming Guide">
    <meta id="book-root" name="book-root" content="../">
    <meta id="book-json" name="book-json" content="../book.json">
    <meta id="devcenter" name="devcenter" content="Mac Dev Center">
    <meta id="devcenter-url" name="devcenter-url" content="http://developer.apple.com/devcenter/mac">
    <meta id="reflib" name="reflib" content="Documentation Archive">
    <meta id="book-assignments" name="book-assignments" content="{Type/Guide}, {Topic/Audio, Video, &amp; Visual Effects}">
    
    
    <meta id="copyright" name="copyright" content="Copyright 2018 Apple Inc. All Rights Reserved.">
    <meta id="xcode-display" name="xcode-display" content="render">
    <meta id="IndexTitle" name="IndexTitle" content="Multimedia Programming Guide (Legacy): Using Audio">
    <meta id="resources-uri" name="resources-uri" content="../../../../../Resources/1282">
    <link id="book-index-page" rel="Start" title="Multimedia Programming Guide" type="text/html" href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/index.html">
    <link id="next-page" rel="Next" type="text/html" href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingVideo/UsingVideo.html">
    <link id="previous-page" rel="Prev" type="text/html" href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Introduction/Introduction.html">
    <link rel="stylesheet" type="text/css" href="./Multimedia Programming Guide _files/screen.css">
    
    <!-- xcode_css -->
    <link rel="stylesheet" type="text/css" href="./Multimedia Programming Guide _files/feedback.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta id="platforms" name="platforms" content="">
</head>    
<body class="isShowingTOC" id=""><a name="//apple_ref/doc/uid/TP40009767-CH2" title="Using Audio"></a>
    <div id="_omniture_top">
    <!-- SiteCatalyst code version: H.8. Copyright 1997-2006 Omniture, Inc. -->
    <script type="text/javascript">
    /* RSID: */
    var s_account="appleglobal,appleusdeveloper,dappdeveloperlib"
    </script>

    <script type="text/javascript" src="./Multimedia Programming Guide _files/s_code_h.js"></script>
    <script type="text/javascript">
    s.pageName=AC.Tracking.pageName();
    s.channel="www.us.developer"

    /************* DO NOT ALTER ANYTHING BELOW THIS LINE ! **************/
    var s_code=s.t();if(s_code)document.write(s_code)</script>
    <!-- End SiteCatalyst code version: H.8. -->
    </div>

    <div id="adcHeader" class="hideOnPrint hideInXcode">
        <div id="ssi_Header" class="hideInXcode unified">
            <a id="ssi_LibraryTitle" href="https://developer.apple.com/library/archive/navigation/" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/navigation/_1&quot;;return this.s_oc?this.s_oc(e):true">Documentation Archive</a>
            <a id="ssi_AppleDeveloperConnection" href="https://developer.apple.com/" onclick="s_objectID=&quot;https://developer.apple.com/_1&quot;;return this.s_oc?this.s_oc(e):true">Developer</a>
            <div id="ssi_SearchButton" role="button" title="Search">Search</div>
        </div>
        <form id="ssi_SearchMenu" method="get" action="https://developer.apple.com/library/archive/search/" accept-charset="utf-8">
            <label for="adcsearch">Search Documentation Archive</label>
            
            
    
            <input type="search" id="ssi_SearchField" name="q" accesskey="s" results="5">
        </form>
    </div>

    <header id="header">
        <div id="title" role="banner">
            <h1>Multimedia Programming Guide</h1>
            <span id="file_links">
                <a id="PDF_link" role="button" tabindex="4" rel="alternate" title="Download PDF" class=""><span id="pdf_icon"></span>PDF</a>
                <a id="Companion_link" role="button" tabindex="3" title="Download Companion File" class=""><span id="companion_icon"></span>Companion File</a>
            </span>
        </div>
        <ul id="headerButtons" class="hideOnPrint" role="toolbar">
            <li id="toc_button" style="">
                <button tabindex="5" id="table_of_contents" class="open" role="checkbox" aria-label="Show Table of Contents"><span class="disclosure"></span>Table of Contents</button>
            </li>
            <li id="jumpto_button" style="display:none" role="navigation"><select tabindex="6" id="jumpTo"><option value="top">Jump To…</option></select></li>
            <li id="downloadSample_button" style="display:none">
                <a id="Sample_link"><button id="Sample_button">Download Sample Code</button></a>
            </li>
        </ul>
    </header>
    <nav id="tocContainer" tabindex="7" class="isShowingTOC">
        <ul id="toc" role="tree"><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH1-SW1"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Introduction/Introduction.html#//apple_ref/doc/uid/TP40009767-CH1-SW1">Introduction</a></span></li><li class="children open" data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW6" role="treeitem"><span class="disclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW6">Using Audio</a></span><ul><li class="children  open" data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW9" role="treeitem"><span class="disclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW9">The Basics: Audio Codecs, Supported Audio Formats, and Audio Sessions</a></span><ul><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW33"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW33">iOS Hardware and Software Audio Codecs</a></span></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW34"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW34">Audio Sessions</a></span></li></ul></li><li class="children  open" data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW35" role="treeitem"><span class="disclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW35">Playing Audio</a></span><ul><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW43"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW43">Playing Audio Items with iPod Library Access</a></span></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW1"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW1">Playing UI Sound Effects or Invoking Vibration Using System Sound Services</a></span></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW2"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW2">Playing Sounds Easily with the AVAudioPlayer Class</a></span></li><li class="children " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW5" role="treeitem"><span class="disclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW5">Playing Sounds with Control Using Audio Queue Services</a></span><ul><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW38"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW38">Creating an Audio Queue Object</a></span></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW39"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW39">Controlling the Playback Level</a></span></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW29"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW29">Indicating Playback Level</a></span></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW40"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW40">Playing Multiple Sounds Simultaneously</a></span></li></ul></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW3"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW3">Playing Sounds with Positioning Using OpenAL</a></span></li></ul></li><li class="children  open" data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW7" role="treeitem"><span class="disclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW7">Recording Audio</a></span><ul><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW14"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW14">Recording with the AVAudioRecorder Class</a></span></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW16"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW16">Recording with Audio Queue Services</a></span></li></ul></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW8"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW8">Parsing Streamed Audio</a></span></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW4"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW4">Audio Unit Support in iOS</a></span></li><li class="children " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW10" role="treeitem"><span class="disclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW10">Best Practices for iOS Audio</a></span><ul><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW41"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW41">Tips for Using Audio</a></span></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH2-SW28"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW28">Preferred Audio Formats in iOS</a></span></li></ul></li></ul></li><li class="children " data-aref="//apple_ref/doc/uid/TP40009767-CH3-SW1" role="treeitem"><span class="disclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingVideo/UsingVideo.html#//apple_ref/doc/uid/TP40009767-CH3-SW1">Using Video</a></span><ul><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH3-SW47"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingVideo/UsingVideo.html#//apple_ref/doc/uid/TP40009767-CH3-SW47">Recording and Editing Video</a></span></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH3-SW12"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingVideo/UsingVideo.html#//apple_ref/doc/uid/TP40009767-CH3-SW12">Playing Video Files</a></span></li></ul></li><li class=" " data-aref="//apple_ref/doc/uid/TP40009767-CH99-SW1"><span class="nodisclosure"></span><span class="sectionName"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/RevisionHistory.html#//apple_ref/doc/uid/TP40009767-CH99-SW1">Revision History</a></span></li></ul>
    </nav>

    <article id="contents" tabindex="0" role="main" class="isShowingTOC">
        <div id="pageNavigationLinks_top" class="pageNavigationLinks">
            <a class="nextLink" rel="next" href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingVideo/UsingVideo.html" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_1&quot;;return this.s_oc?this.s_oc(e):true">Next</a><a class="previousLink" rel="prev" href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Introduction/Introduction.html" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Intr_1&quot;;return this.s_oc?this.s_oc(e):true">Previous</a>
        </div>
        <a id="top" name="top"></a>
        <a id="INDEX" href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/index.html" style="display:none;" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/inde_1&quot;;return this.s_oc?this.s_oc(e):true"></a>
        <div id="legacyOuterWrapper" role="alert" class="show"><div align="center" id="watermark"><div class="legacybox">
<h1>Retired Document<span id="LegacyNoticeCloseBox" class="closebutton"></span></h1><p><b>Important:</b>
This document may not represent best practices for current development. Links to downloads and other resources may no longer be valid. For information on media playback, see <em><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MediaPlaybackGuide/Contents/Resources/en.lproj/Introduction/Introduction.html#//apple_ref/doc/uid/TP40016757" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MediaPlaybackGuid_1&quot;;return this.s_oc?this.s_oc(e):true">Media Playback Programming Guide</a></em>.</p></div></div></div>
        <a name="//apple_ref/doc/uid/TP40009767-CH2-SW6" title="Using Audio"></a><h1 id="pageTitle">Using Audio</h1><div class="importantbox clear"><aside><a name="//apple_ref/doc/uid/TP40009767-CH2-DontLinkElementID_5" title="Important"></a><p><strong>Important:</strong>&nbsp;This document contains information that used to be in <em><a href="https://developer.apple.com/library/archive/documentation/iPhone/Conceptual/iPhoneOSProgrammingGuide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40007072" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/iPhone/Conceptual/iPhoneOSProgrammingGu_1&quot;;return this.s_oc?this.s_oc(e):true">App Programming Guide for iOS</a></em>. The information in this document has <em>not</em> been updated specifically for iOS 4.0. </p><p></p></aside></div><p>iOS offers a rich set of tools for working with sound in your application. These tools are arranged into <span class="pediaLink" data-header="Framework" data-contents="A framework is a bundle (a structured directory) that contains a dynamic shared library along with associated resources, such as nib files, image files, and header files. "><a data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/General/Conceptual/DevPedia-CocoaCore/F_1&quot;;return this.s_oc?this.s_oc(e):true" data-href="../../../../General/Conceptual/DevPedia-CocoaCore/Framework.html#//apple_ref/doc/uid/TP40008195-CH56">frameworks</a></span> according to the features they provide, as follows:</p><ul class="ul"><li class="li"><p>Use the <em class="newTerm">Media Player framework</em> to play songs, audio books, or audio podcasts from a user’s iPod library. For details, see <em><a href="https://developer.apple.com/documentation/mediaplayer" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/mediaplayer_1&quot;;return this.s_oc?this.s_oc(e):true">Media Player Framework Reference</a></em>, <em><a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/iPodLibraryAccess_Guide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40008765" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/Audio/Conceptual/iPodLibraryAccess_Guid_1&quot;;return this.s_oc?this.s_oc(e):true">iPod Library Access Programming Guide</a></em>, and the <em><a href="https://developer.apple.com/library/archive/samplecode/AddMusic/Introduction/Intro.html#//apple_ref/doc/uid/DTS40008845" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/samplecode/AddMusic/Introduction/Intro.html#//apple_r_1&quot;;return this.s_oc?this.s_oc(e):true">AddMusic</a></em> sample code project.</p></li><li class="li"><p>Use the <em class="newTerm">AV Foundation framework</em> to play and record audio using a simple Objective-C interface. For details, see <em><a href="https://developer.apple.com/documentation/avfoundation" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation_1&quot;;return this.s_oc?this.s_oc(e):true">AV Foundation Framework Reference</a></em> and the <em><a href="https://developer.apple.com/library/archive/samplecode/avTouch/Introduction/Intro.html#//apple_ref/doc/uid/DTS40008636" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/samplecode/avTouch/Introduction/Intro.html#//apple_re_1&quot;;return this.s_oc?this.s_oc(e):true">avTouch</a></em> sample code project.</p></li><li class="li"><p>Use the <em class="newTerm">Audio Toolbox framework</em> to play audio with synchronization capabilities, access packets of incoming audio, parse audio streams, convert audio formats, and record audio with access to individual packets. For details, see <em><a href="https://developer.apple.com/documentation/audiotoolbox" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox_1&quot;;return this.s_oc?this.s_oc(e):true">Audio Toolbox Framework Reference</a></em> and the <em><!--a target="_self" -->SpeakHere<!--/a--></em> sample code project.</p></li><li class="li"><p>Use the <em class="newTerm">Audio Unit framework</em> to connect to and use audio processing plug-ins. For details, see <em><a href="https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioUnitHostingGuide_iOS/Introduction/Introduction.html#//apple_ref/doc/uid/TP40009492" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioUnitHostingG_1&quot;;return this.s_oc?this.s_oc(e):true">Audio Unit Hosting Guide for iOS</a></em>.</p></li><li class="li"><p>Use the <em class="newTerm">OpenAL framework</em> to provide positional audio playback in games and other applications. iOS supports OpenAL 1.1. For information on OpenAL, see the <span class="content_text"><a href="http://openal.org/" class="urlLink" rel="external" onclick="s_objectID=&quot;http://openal.org/_1&quot;;return this.s_oc?this.s_oc(e):true">OpenAL</a></span> website,  <em><a href="https://developer.apple.com/library/archive/technotes/tn2199/_index.html#//apple_ref/doc/uid/DTS40007999" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/technotes/tn2199/_index.html#//apple_ref/doc/uid/DTS4_1&quot;;return this.s_oc?this.s_oc(e):true">OpenAL FAQ for iPhone OS</a></em>, and the <em><!--a target="_self" -->oalTouch<!--/a--></em> sample code project.</p></li></ul><p>To allow your code to use the features of an audio framework, add that framework to your Xcode project, link against it in any relevant targets, and add an appropriate <code>#import</code> statement near the top of relevant source files. For example, to provide access to the AV Foundation framework in a source file, add a <code>#import &lt;AVFoundation/AVFoundation.h&gt;</code> statement near the top of the file. For detailed information on how to add frameworks to your project, see <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/XcodeProjectManagement/130-Files_in_Projects/project_files.html#//apple_ref/doc/uid/TP40002666" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/XcodeProjectM_1&quot;;return this.s_oc?this.s_oc(e):true">Files in Projects</a></span> in <em><a href="https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/XcodeProjectManagement/000-Introduction/introduction.html#//apple_ref/doc/uid/TP40006917" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/XcodeProjectM_2&quot;;return this.s_oc?this.s_oc(e):true">Xcode Project Management Guide</a></em>.</p><div class="importantbox clear"><aside><a name="//apple_ref/doc/uid/TP40009767-CH2-DontLinkElementID_6" title="Important"></a><p><strong>Important:</strong>&nbsp;To use the features of the Audio Unit framework, add the <em>Audio Toolbox</em> framework to your Xcode project and link against it in any relevant targets. Then add a <code>#import &lt;AudioToolbox/AudioToolbox.h&gt;</code> statement near the top of relevant source files.</p><p></p></aside></div><p>This section on sound provides a quick introduction to implementing iOS audio features, as listed here:</p><ul class="ul"><li class="li"><p>To play songs, audio podcasts, and audio books from a user’s iPod library, see <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW43" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_2&quot;;return this.s_oc?this.s_oc(e):true">Playing Audio Items with iPod Library Access</a></span>.</p></li><li class="li"><p>To play and record audio in the fewest lines of code, use the AV Foundation framework. See <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW2" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_3&quot;;return this.s_oc?this.s_oc(e):true">Playing Sounds Easily with the AVAudioPlayer Class</a></span> and <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW14" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_4&quot;;return this.s_oc?this.s_oc(e):true">Recording with the AVAudioRecorder Class</a></span>.</p></li><li class="li"><p>To provide full-featured audio playback including stereo positioning, level control, and simultaneous sounds, use OpenAL. See <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW3" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_5&quot;;return this.s_oc?this.s_oc(e):true">Playing Sounds with Positioning Using OpenAL</a></span>.</p></li><li class="li"><p>To provide lowest latency audio, especially when doing simultaneous input and output (such as for a VoIP application), use the I/O unit or the Voice Processing I/O unit. See <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW4" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_6&quot;;return this.s_oc?this.s_oc(e):true">Audio Unit Support in iOS</a></span>.</p></li><li class="li"><p>To play sounds with the highest degree of control, including support for synchronization, use Audio Queue Services. See <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW5" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_7&quot;;return this.s_oc?this.s_oc(e):true">Playing Sounds with Control Using Audio Queue Services</a></span>. Audio Queue Services also supports recording and provides access to incoming audio packets, as described in <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW16" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_8&quot;;return this.s_oc?this.s_oc(e):true">Recording with Audio Queue Services</a></span>.</p></li><li class="li"><p>To parse audio streamed from a network connection, use Audio File Stream Services. See <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW8" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_9&quot;;return this.s_oc?this.s_oc(e):true">Parsing Streamed Audio</a></span>.</p></li><li class="li"><p>To play user-interface sound effects, or to invoke vibration on devices that provide that feature, use System Sound Services. See <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW1" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_10&quot;;return this.s_oc?this.s_oc(e):true">Playing UI Sound Effects or Invoking Vibration Using System Sound Services</a></span>.</p></li></ul><p>Be sure to read the next section, <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW9" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_11&quot;;return this.s_oc?this.s_oc(e):true">The Basics: Audio Codecs, Supported Audio Formats, and Audio Sessions</a></span>, for critical information on how audio works in iOS. Also read <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW10" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_12&quot;;return this.s_oc?this.s_oc(e):true">Best Practices for iOS Audio</a></span>, which offers guidelines and lists the audio and file formats to use for best performance and best user experience.</p><p>When you’re ready to dig deeper, the <span class="content_text"><a href="http://developer.apple.com/iphone/" class="browserLink" onclick="s_objectID=&quot;http://developer.apple.com/iphone/_1&quot;;return this.s_oc?this.s_oc(e):true">iOS Dev Center</a></span> contains guides, reference books, sample code, and more. For in-depth explanations of audio development in iOS, see <em><a href="https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview/Introduction/Introduction.html#//apple_ref/doc/uid/TP40003577" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview_1&quot;;return this.s_oc?this.s_oc(e):true">Core Audio Overview</a></em>, <em><a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40007875" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammin_1&quot;;return this.s_oc?this.s_oc(e):true">Audio Session Programming Guide</a></em>, <em><a href="https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioQueueProgrammingGuide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40005343" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioQueueProgram_1&quot;;return this.s_oc?this.s_oc(e):true">Audio Queue Services Programming Guide</a></em>, <em><a href="https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioUnitHostingGuide_iOS/Introduction/Introduction.html#//apple_ref/doc/uid/TP40009492" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioUnitHostingG_2&quot;;return this.s_oc?this.s_oc(e):true">Audio Unit Hosting Guide for iOS</a></em>, and <em><a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/iPodLibraryAccess_Guide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40008765" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/Audio/Conceptual/iPodLibraryAccess_Guid_2&quot;;return this.s_oc?this.s_oc(e):true">iPod Library Access Programming Guide</a></em>.</p><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW9" title="The Basics: Audio Codecs, Supported Audio Formats, and Audio Sessions"></a><h2 class="jump">The Basics: Audio Codecs, Supported Audio Formats, and Audio Sessions</h2><p>To get oriented toward iOS audio development, it’s important to understand a few critical things about the hardware and software architecture of iOS devices—described in this section.</p><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW33" title="iOS Hardware and Software Audio Codecs"></a><h3 class="jump">iOS Hardware and Software Audio Codecs</h3><p>To ensure optimum performance and quality, you need to pick the right audio format and audio codec type. Starting in iOS 3.0, most  audio formats can use software-based encoding (for recording) and decoding (for playback). Software codecs support simultaneous playback of multiple sounds, but may entail significant CPU overhead.</p><p>Hardware-assisted decoding provides excellent performance—but does not support simultaneous playback of multiple sounds. If you need to maximize video frame rate in your application, minimize the CPU impact of your audio playback by using uncompressed audio or the IMA4 format, or use hardware-assisted decoding of your compressed audio assets.</p><p>For best-practice advice on picking an audio format, see <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW28" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_13&quot;;return this.s_oc?this.s_oc(e):true">Preferred Audio Formats in iOS</a></span>.</p><p><span class="content_text">Table 1-1</span> describes the playback audio codecs available on iOS devices.</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW48" title="Table 1-1Audio playback formats and codecs"></a><div class="tableholder"><table class="graybox" border="0" cellspacing="0" cellpadding="5"><caption class="tablecaption"><strong class="caption_number">Table 1-1</strong>&nbsp;&nbsp;Audio playback formats and codecs</caption><tbody><tr><th scope="col" class="TableHeading_TableRow_TableCell"><p>Audio decoder/playback format</p></th><th scope="col" class="TableHeading_TableRow_TableCell"><p>Hardware-assisted decoding</p></th><th scope="col" class="TableHeading_TableRow_TableCell"><p>Software-based decoding</p></th></tr><tr><td scope="row"><p>AAC (MPEG-4 Advanced Audio Coding)</p></td><td><p>Yes</p></td><td><p>Yes, starting in iOS 3.0</p></td></tr><tr><td scope="row"><p>ALAC (Apple Lossless)</p></td><td><p>Yes</p></td><td><p>Yes, starting in iOS 3.0</p></td></tr><tr><td scope="row"><p>HE-AAC (MPEG-4 High Efficiency AAC)</p></td><td><p>Yes</p></td><td><p>-</p></td></tr><tr><td scope="row"><p>iLBC (internet Low Bitrate Codec, another format for speech)</p></td><td><p>-</p></td><td><p>Yes</p></td></tr><tr><td scope="row"><p>IMA4 (IMA/ADPCM)</p></td><td><p>-</p></td><td><p>Yes</p></td></tr><tr><td scope="row"><p>Linear PCM (uncompressed, linear pulse-code modulation)</p></td><td><p>-</p></td><td><p>Yes</p></td></tr><tr><td scope="row"><p>MP3 (MPEG-1 audio layer 3)</p></td><td><p>Yes</p></td><td><p>Yes, starting in iOS 3.0</p></td></tr><tr><td scope="row"><p>µ-law and a-law</p></td><td><p>-</p></td><td><p>Yes</p></td></tr></tbody></table></div><p>When using hardware-assisted decoding, the device can play <em>only a single instance</em> of one of the supported formats at a time. For example, if you are playing a stereo MP3 sound using the hardware codec, a second simultaneous MP3 sound will use software decoding. Similarly, you cannot simultaneously play an AAC and an ALAC sound using hardware. If the iPod application is playing an AAC or MP3 sound in the background, it has claimed the hardware codec; your application then plays AAC, ALAC, and MP3 audio using software decoding.</p><p>To play multiple sounds with best performance, or to efficiently play sounds while the iPod is playing in the background, use linear PCM (uncompressed) or IMA4 (compressed) audio.</p><p>To learn how to check at runtime which hardware and software codecs are available on a device, read the discussion for the <code><a href="https://developer.apple.com/documentation/audiotoolbox/kaudioformatproperty_hardwarecodeccapabilities" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/kaudioformatproperty_hardwarecodeccapabili_1&quot;;return this.s_oc?this.s_oc(e):true">kAudioFormatProperty_HardwareCodecCapabilities</a></code> constant in <em><a href="https://developer.apple.com/documentation/audiotoolbox/audio_format_services" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/audio_format_services_1&quot;;return this.s_oc?this.s_oc(e):true">Audio Format Services Reference</a></em> and read Technical Q&amp;A QA1663, “Determining the availability of the AAC hardware encoder at runtime.”</p><p>To summarize how iOS supports audio formats for single or multiple playback:</p><ul class="ul"><li class="li"><p><em class="newTerm">Linear PCM and IMA4 (IMA/ADPCM)</em> You can play multiple linear PCM or IMA4 sounds simultaneously in iOS without incurring CPU resource problems. The same is true for the iLBC speech-quality format, and for the µ-law and a-law compressed formats. When using compressed formats, check the sound quality to ensure it meets your needs.</p></li><li class="li"><p><em class="newTerm">AAC, HE-AAC, MP3, and ALAC (Apple Lossless)</em> Playback for AAC, HE-AAC, MP3, and ALAC sounds can use efficient hardware-assisted decoding on iOS devices, but these codecs all share a single hardware path. The device can play only a single instance of one of these formats at a time using hardware-assisted decoding.</p></li></ul><p>The single hardware path for AAC, HE-AAC, MP3, and ALAC playback has implications for “play along” style applications, such as a virtual piano. If the user is playing a song in one of these three formats in the iPod application, then your application—to play along over that audio—will employ software decoding.</p><p><span class="content_text">Table 1-2</span> describes the recording audio codecs available on iOS devices.</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW49" title="Table 1-2Audio recording formats and codecs"></a><div class="tableholder"><table class="graybox" border="0" cellspacing="0" cellpadding="5"><caption class="tablecaption"><strong class="caption_number">Table 1-2</strong>&nbsp;&nbsp;Audio recording formats and codecs</caption><tbody><tr><th scope="col" class="TableHeading_TableRow_TableCell"><p>Audio encoder/recording format</p></th><th scope="col" class="TableHeading_TableRow_TableCell"><p>Hardware-assisted encoding</p></th><th scope="col" class="TableHeading_TableRow_TableCell"><p>Software-based encoding</p></th></tr><tr><td scope="row"><p>AAC (MPEG-4 Advanced Audio Coding)</p></td><td><p>Yes, starting in iOS 3.1 for iPhone 3GS and iPod touch (2nd generation)</p><p>Yes, starting in iOS 3.2 for iPad</p></td><td><p>Yes, starting in iOS 4.0 for iPhone 3GS and iPod touch (2nd generation)</p></td></tr><tr><td scope="row"><p>ALAC (Apple Lossless)</p></td><td><p>-</p></td><td><p>Yes</p></td></tr><tr><td scope="row"><p>iLBC (internet Low Bitrate Codec, for speech)</p></td><td><p>-</p></td><td><p>Yes</p></td></tr><tr><td scope="row"><p>IMA4 (IMA/ADPCM)</p></td><td><p>-</p></td><td><p>Yes</p></td></tr><tr><td scope="row"><p>Linear PCM (uncompressed, linear pulse-code modulation)</p></td><td><p>-</p></td><td><p>Yes</p></td></tr><tr><td scope="row"><p>µ-law and a-law</p></td><td><p>-</p></td><td><p>Yes</p></td></tr></tbody></table></div></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW34" title="Audio Sessions"></a><h3 class="jump">Audio Sessions</h3><p>The iOS audio session APIs let you define your application’s general audio behavior and design it to work well within the larger audio context of the device it’s running on. These APIs are described in <em><a href="https://developer.apple.com/documentation/audiotoolbox/audio_session_services" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/audio_session_services_1&quot;;return this.s_oc?this.s_oc(e):true">Audio Session Services Reference</a></em> and <em><a href="https://developer.apple.com/documentation/avfoundation/avaudiosession" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudiosession_1&quot;;return this.s_oc?this.s_oc(e):true">AVAudioSession Class Reference</a></em>. Using these APIs, you can specify such behaviors as:</p><ul class="ul"><li class="li"><p>Whether or not your audio should be silenced by the Silent switch (on iPhone, this is called the <em>Ring/Silent switch</em>)</p></li><li class="li"><p>Whether or not your audio should stop upon screen lock</p></li><li class="li"><p>Whether other audio, such as from the iPod, should continue playing or be silenced when your audio starts</p></li></ul><p>The audio session APIs also let you respond to user actions, such as the plugging in or unplugging of headsets, and to events that use the device’s sound hardware, such as Clock and Calendar alarms and incoming phone calls.</p><p>The audio session APIs provide three programmatic features, described in <span class="content_text">Table 1-3</span>.</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW11" title="Table 1-3Features provided by the audio session APIs"></a><div class="tableholder"><table class="graybox" border="0" cellspacing="0" cellpadding="5"><caption class="tablecaption"><strong class="caption_number">Table 1-3</strong>&nbsp;&nbsp;Features provided by the audio session APIs</caption><tbody><tr><th scope="col" class="TableHeading_TableRow_TableCell"><p>Audio session feature</p></th><th scope="col" class="TableHeading_TableRow_TableCell"><p>Description</p></th></tr><tr><td scope="row"><p>Setting categories</p></td><td><p>A category is a key that identifies a set of audio behaviors for your application. By setting a category, you indicate your audio intentions to iOS, such as whether your audio should continue when the screen locks. There are six categories, described in <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/HandlingAudioInterruptions/HandlingAudioInterruptions.html#//apple_ref/doc/uid/TP40007875-CH4" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammin_2&quot;;return this.s_oc?this.s_oc(e):true">Responding to Interruptions</a></span>. You can fine-tune the behavior of some categories, as explained in <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/AudioSessionBasics/AudioSessionBasics.html#//apple_ref/doc/uid/TP40007875-CH3-SW2" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammin_3&quot;;return this.s_oc?this.s_oc(e):true">Use Modes to Specialize the Category</a></span>.</p></td></tr><tr><td scope="row"><p>Handling interruptions and route changes</p></td><td><p>Your audio session posts <span class="pediaLink" data-header="Message" data-contents="A message is the name of a method, and any parameters associated with it, that are sent to, and executed by, an object. "><a data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/General/Conceptual/DevPedia-CocoaCore/M_1&quot;;return this.s_oc?this.s_oc(e):true" data-href="../../../../General/Conceptual/DevPedia-CocoaCore/Message.html#//apple_ref/doc/uid/TP40008195-CH59">messages</a></span> when your audio is interrupted, when an interruption ends, and when the hardware audio route changes. These messages let you respond gracefully to changes in the larger audio environment—such as an interruption due to an incoming phone call. For details, see <span class="content_text"><!--a target="_self" -->Handling Audio Hardware Route Changes<!--/a--></span> and <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/AudioGuidelinesByAppType/AudioGuidelinesByAppType.html#//apple_ref/doc/uid/TP40007875-CH11" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammin_4&quot;;return this.s_oc?this.s_oc(e):true">Audio Guidelines By App Type</a></span>.</p></td></tr><tr><td scope="row"><p>Optimizing for hardware characteristics</p></td><td><p>You can query the audio session to discover characteristics of the device your application is running on, such as hardware sample rate, number of hardware channels, and whether audio input is available. For details, see <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/RequestingPermission/RequestingPermission.html#//apple_ref/doc/uid/TP40007875-CH13" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammin_5&quot;;return this.s_oc?this.s_oc(e):true">Optimizing for Device Hardware</a></span>.</p></td></tr></tbody></table></div><p>There are two interfaces for working with the audio session:</p><ul class="ul"><li class="li"><p>A streamlined, objective-C interface that gives you access to the core audio session features and is described in <em><a href="https://developer.apple.com/documentation/avfoundation/avaudiosession" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudiosession_2&quot;;return this.s_oc?this.s_oc(e):true">AVAudioSession Class Reference</a></em> and <em><a href="https://developer.apple.com/documentation/avfoundation/avaudiosessiondelegate" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudiosessiondelegate_1&quot;;return this.s_oc?this.s_oc(e):true">AVAudioSessionDelegate Protocol Reference</a></em>.</p></li><li class="li"><p>A C-based interface that provides comprehensive access to all basic and advanced audio session features and is described in <em><a href="https://developer.apple.com/documentation/audiotoolbox/audio_session_services" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/audio_session_services_2&quot;;return this.s_oc?this.s_oc(e):true">Audio Session Services Reference</a></em>.</p></li></ul><p>You can mix and match audio session code from AV Foundation and Audio Session Services—the interfaces are completely compatible.</p><p>An audio session comes with some default behavior that you can use to get started in development. However, except for certain special cases, the default behavior is unsuitable for a shipping application that uses audio.</p><p>For example, when using the default audio session, audio in your application stops when the Auto-Lock period times out and the screen locks. If you want to ensure that playback continues with the screen locked, include the following lines in your application’s <span class="pediaLink" data-header="Initialization" data-contents="Initialization is the stage of object creation that makes a newly allocated object usable by setting its state to reasonable initial values. "><a data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/General/Conceptual/DevPedia-CocoaCore/I_1&quot;;return this.s_oc?this.s_oc(e):true" data-href="../../../../General/Conceptual/DevPedia-CocoaCore/Initialization.html#//apple_ref/doc/uid/TP40008195-CH21">initialization</a></span> code:</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>NSError *setCategoryErr = nil;<span></span></pre></td></tr><tr><td scope="row"><pre>NSError *activationErr  = nil;<span></span></pre></td></tr><tr><td scope="row"><pre>[[AVAudioSession sharedInstance]<span></span></pre></td></tr><tr><td scope="row"><pre>              setCategory: AVAudioSessionCategoryPlayback<span></span></pre></td></tr><tr><td scope="row"><pre>                    error: &amp;setCategoryErr];<span></span></pre></td></tr><tr><td scope="row"><pre>[[AVAudioSession sharedInstance]<span></span></pre></td></tr><tr><td scope="row"><pre>                setActive: YES<span></span></pre></td></tr><tr><td scope="row"><pre>                    error: &amp;activationErr];<span></span></pre></td></tr></tbody></table></div><p>The <code><a href="https://developer.apple.com/documentation/avfoundation/avaudiosessioncategoryplayback" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudiosessioncategoryplayback_1&quot;;return this.s_oc?this.s_oc(e):true">AVAudioSessionCategoryPlayback</a></code> category ensures that playback continues when the screen locks. Activating the audio session puts the specified category into effect.</p><p>How you handle the interruption caused by an incoming phone call or Clock or Calendar alarm depends on the audio technology you are using, as shown in <span class="content_text">Table 1-4</span>.</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW17" title="Table 1-4Handling audio interruptions"></a><div class="tableholder"><table class="graybox" border="0" cellspacing="0" cellpadding="5"><caption class="tablecaption"><strong class="caption_number">Table 1-4</strong>&nbsp;&nbsp;Handling audio interruptions</caption><tbody><tr><th scope="col" class="TableHeading_TableRow_TableCell"><p>Audio technology</p></th><th scope="col" class="TableHeading_TableRow_TableCell"><p>How interruptions work</p></th></tr><tr><td scope="row"><p>AV&nbsp;Foundation&nbsp;framework</p></td><td><p>The <code>AVAudioPlayer</code> and <code>AVAudioRecorder</code> classes provide delegate methods for interruption start and end. Implement these methods to update your user interface and optionally, after interruption ends, to resume paused playback. The system automatically pauses playback or recording upon interruption, and reactivates your audio session when you resume playback or recording.</p><p>If you want to save and restore playback position between application launches, save playback position on interruption as well as on application quit.</p></td></tr><tr><td scope="row"><p>Audio Queue Services, I/O&nbsp;audio&nbsp;unit</p></td><td><p>These technologies put your application in control of handling interruptions. You are responsible for saving playback or recording position and reactivating your audio session after interruption ends. Implement the <code>AVAudioSession</code> interruption delegate methods or write an interruption listener callback function.</p></td></tr><tr><td scope="row"><p>OpenAL</p></td><td><p>When using OpenAL for playback, implement the <code>AVAudioSession</code> interruption delegate methods or write an interruption listener callback function—as when using Audio Queue Services. However, the delegate or callback must additionally manage the OpenAL context.</p></td></tr><tr><td scope="row"><p>System Sound Services</p></td><td><p>Sounds played using System Sound Services go silent when an interruption starts. They can automatically be used again if the interruption ends. Applications cannot influence the interruption behavior for sounds that use this playback technology.</p></td></tr></tbody></table></div><p>Every iOS application—with rare exception—should actively manage its audio session. For a complete explanation of how to do this, read <em><a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40007875" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammin_6&quot;;return this.s_oc?this.s_oc(e):true">Audio Session Programming Guide</a></em>. To ensure that your application conforms to Apple recommendations for audio session behavior, read <span class="content_text"><!--a target="_self" -->Sound<!--/a--></span>in <em><!--a target="_self" -->iOS Human Interface Guidelines<!--/a--></em>.</p></section></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW35" title="Playing Audio"></a><h2 class="jump">Playing Audio</h2><p>This section introduces you to playing sounds in iOS using iPod library access, System Sound Services, Audio Queue Services, the AV Foundation framework, and OpenAL.</p><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW43" title="Playing Audio Items with iPod Library Access"></a><h3 class="jump">Playing Audio Items with iPod Library Access</h3><p>Starting in iOS 3.0, iPod library access lets your application play a user’s songs, audio books, and audio podcasts. The API design makes basic playback very simple while also supporting advanced searching and playback control.</p><p>As shown in <span class="content_text">Figure 1-1</span>, your application has two ways to retrieve media items. The media item picker, shown on the left, is an easy-to-use, pre-packaged view controller that behaves like the built-in iPod application’s music selection interface. For many applications, this is sufficient. If the picker doesn’t provide the specialized access control you want, the media query interface will. It supports predicate-based specification of items from the iPod library.</p><figure class="figure"><a name="//apple_ref/doc/uid/TP40009767-CH2-SW45" title="Figure 1-1Using iPod library access"></a><figcaption><strong class="caption_number">Figure 1-1</strong>&nbsp;&nbsp;Using iPod library access</figcaption><img src="./Multimedia Programming Guide _files/iPodLibraryAccessOverview.jpg" alt="Using iPod library access" width="326" height="256"></figure><p>As depicted in the figure to the right of your application, you then play the retrieved media items using the music player provided by this API.</p><p>For a complete explanation of how to add media item playback to your application, see <em><a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/iPodLibraryAccess_Guide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40008765" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/Audio/Conceptual/iPodLibraryAccess_Guid_3&quot;;return this.s_oc?this.s_oc(e):true">iPod Library Access Programming Guide</a></em>. For a code example, see the <em><a href="https://developer.apple.com/library/archive/samplecode/AddMusic/Introduction/Intro.html#//apple_ref/doc/uid/DTS40008845" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/samplecode/AddMusic/Introduction/Intro.html#//apple_r_2&quot;;return this.s_oc?this.s_oc(e):true">AddMusic</a></em> sample code project.</p></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW1" title="Playing UI Sound Effects or Invoking Vibration Using System Sound Services"></a><h3 class="jump">Playing UI Sound Effects or Invoking Vibration Using System Sound Services</h3><p>To play user-interface sound effects (such as button clicks), or to invoke vibration on devices that support it, use System Sound Services. This compact interface is described in <em><a href="https://developer.apple.com/documentation/audiotoolbox/system_sound_services" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/system_sound_services_1&quot;;return this.s_oc?this.s_oc(e):true">System Sound Services Reference</a></em>. You can find sample code in the <em><!--a target="_self" -->Audio UI Sounds (SysSound)<!--/a--></em> sample in the <span class="content_text"><a href="http://developer.apple.com/iphone/" class="browserLink" onclick="s_objectID=&quot;http://developer.apple.com/iphone/_2&quot;;return this.s_oc?this.s_oc(e):true">iOS Dev Center</a></span>.</p><div class="notebox"><aside><a name="//apple_ref/doc/uid/TP40009767-CH2-SW36" title="Note"></a><p><strong>Note:</strong>&nbsp;Sounds played with System Sound Services are not subject to configuration using your audio session. As a result, you cannot keep the behavior of System Sound Services audio in line with other audio behavior in your application. This is the most important reason to avoid using System Sound Services for any audio apart from its intended uses.</p><p></p></aside></div><p>The <code><a href="https://developer.apple.com/documentation/audiotoolbox/1405248-audioservicesplaysystemsound" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/1405248-audioservicesplaysystemsound_1&quot;;return this.s_oc?this.s_oc(e):true">AudioServicesPlaySystemSound</a></code> function lets you very simply play short sound files. The simplicity carries with it a few restrictions. Your sound files must be:</p><ul class="ul"><li class="li"><p>No longer than 30 seconds in duration</p></li><li class="li"><p>In linear PCM or IMA4 (IMA/ADPCM) format</p></li><li class="li"><p>Packaged in a <code>.caf</code>, <code>.aif</code>, or <code>.wav</code> file</p></li></ul><p> In addition, when you use the <code>AudioServicesPlaySystemSound</code> function:</p><ul class="ul"><li class="li"><p>Sounds play at the current system audio volume, with no programmatic volume control available</p></li><li class="li"><p>Sounds play immediately</p></li><li class="li"><p>Looping and stereo positioning are unavailable</p></li><li class="li"><p>Simultaneous playback is unavailable: You can play only one sound at a time</p></li></ul><p>The similar <code><a href="https://developer.apple.com/documentation/audiotoolbox/1405202-audioservicesplayalertsound" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/1405202-audioservicesplayalertsound_1&quot;;return this.s_oc?this.s_oc(e):true">AudioServicesPlayAlertSound</a></code> function plays a short sound as an alert. If a user has configured their device to vibrate in Ring Settings, calling this function invokes vibration in addition to playing the sound file. </p><div class="notebox"><aside><a name="//apple_ref/doc/uid/TP40009767-CH2-SW37" title="Note"></a><p><strong>Note:</strong>&nbsp;System-supplied alert sounds and system-supplied user-interface sound effects are not available to your application. For example, using the <code>kSystemSoundID_UserPreferredAlert</code> constant as a parameter to the <code><!--a-->AudioServicesPlayAlertSound<!--/a--></code> function will not play anything.</p><p></p></aside></div><p>To play a sound with the <code><!--a-->AudioServicesPlaySystemSound<!--/a--></code> or <code><!--a-->AudioServicesPlayAlertSound<!--/a--></code> function, first create a sound ID object, as shown in <span class="content_text">Listing 1-1</span>.</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW18" title="Listing 1-1Creating a sound ID object"></a><p class="codesample clear"><strong class="caption_number">Listing 1-1</strong>&nbsp;&nbsp;Creating a sound ID object</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>    // Get the main bundle for the app<span></span></pre></td></tr><tr><td scope="row"><pre>    CFBundleRef mainBundle = CFBundleGetMainBundle ();<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    // Get the URL to the sound file to play. The file in this case<span></span></pre></td></tr><tr><td scope="row"><pre>    // is "tap.aif"<span></span></pre></td></tr><tr><td scope="row"><pre>    soundFileURLRef  = CFBundleCopyResourceURL (<span></span></pre></td></tr><tr><td scope="row"><pre>                           mainBundle,<span></span></pre></td></tr><tr><td scope="row"><pre>                           CFSTR ("tap"),<span></span></pre></td></tr><tr><td scope="row"><pre>                           CFSTR ("aif"),<span></span></pre></td></tr><tr><td scope="row"><pre>                           NULL<span></span></pre></td></tr><tr><td scope="row"><pre>                       );<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    // Create a system sound object representing the sound file<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioServicesCreateSystemSoundID (<span></span></pre></td></tr><tr><td scope="row"><pre>        soundFileURLRef,<span></span></pre></td></tr><tr><td scope="row"><pre>        &amp;soundFileObject<span></span></pre></td></tr><tr><td scope="row"><pre>    );<span></span></pre></td></tr></tbody></table></div><p>Then play the sound, as shown in <span class="content_text">Listing 1-2</span>. </p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW19" title="Listing 1-2Playing a system sound"></a><p class="codesample clear"><strong class="caption_number">Listing 1-2</strong>&nbsp;&nbsp;Playing a system sound</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>- (IBAction) playSystemSound {<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioServicesPlaySystemSound (self.soundFileObject);<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></tbody></table></div><p>In typical use, which includes playing a sound occasionally or repeatedly, retain the sound ID object until your application quits. If you know that you will use a sound only once—for example, in the case of a startup sound—you can destroy the sound ID object immediately after playing the sound, freeing memory.</p><p>Applications running on iOS devices that support vibration can trigger that feature using System Sound Services. You specify the vibrate option with the <code>kSystemSoundID_Vibrate</code> identifier. To trigger it, use the <code>AudioServicesPlaySystemSound</code> function, as shown in <span class="content_text">Listing 1-3</span>. </p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW20" title="Listing 1-3Triggering vibration"></a><p class="codesample clear"><strong class="caption_number">Listing 1-3</strong>&nbsp;&nbsp;Triggering vibration</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>#import &lt;AudioToolbox/AudioToolbox.h&gt;<span></span></pre></td></tr><tr><td scope="row"><pre>#import &lt;UIKit/UIKit.h&gt;<span></span></pre></td></tr><tr><td scope="row"><pre>- (void) vibratePhone {<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioServicesPlaySystemSound (kSystemSoundID_Vibrate);<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></tbody></table></div><p>If your application is running on an iPod touch, this code does nothing.</p></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW2" title="Playing Sounds Easily with the AVAudioPlayer Class"></a><h3 class="jump">Playing Sounds Easily with the AVAudioPlayer Class</h3><p>The <code>AVAudioPlayer</code> class provides a simple <span class="pediaLink" data-header="Objective-C" data-contents="Objective-C defines a small but powerful set of extensions to the ANSI  C programming language that enables sophisticated object-oriented programming. "><a data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/General/Conceptual/DevPedia-CocoaCore/O_1&quot;;return this.s_oc?this.s_oc(e):true" data-href="../../../../General/Conceptual/DevPedia-CocoaCore/ObjectiveC.html#//apple_ref/doc/uid/TP40008195-CH43">Objective-C</a></span> interface for playing sounds. If your application does not require stereo positioning or precise synchronization, and if you are not playing audio captured from a network stream, Apple recommends that you use this class for playback.</p><p>Using an audio player you can:</p><ul class="ul"><li class="li"><p>Play sounds of any duration</p></li><li class="li"><p>Play sounds from files or memory buffers</p></li><li class="li"><p>Loop sounds</p></li><li class="li"><p>Play multiple sounds simultaneously (although not with precise synchronization)</p></li><li class="li"><p>Control relative playback level for each sound you are playing</p></li><li class="li"><p>Seek to a particular point in a sound file, which supports application features such as fast forward and rewind</p></li><li class="li"><p>Obtain audio power data that you can use for audio level metering</p></li></ul><p>The <code>AVAudioPlayer</code> class lets you play sound in any audio format available in iOS, as described in <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW48" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_14&quot;;return this.s_oc?this.s_oc(e):true">Table 1-1</a></span>. For a complete description of this class’s interface, see <em><a href="https://developer.apple.com/documentation/avfoundation/avaudioplayer" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudioplayer_1&quot;;return this.s_oc?this.s_oc(e):true">AVAudioPlayer Class Reference</a></em>.</p><p>To configure an audio player:</p><ol class="ol"><li class="li"><p>Assign a sound file to the audio player.</p></li><li class="li"><p>Prepare the audio player for playback, which acquires the hardware resources it needs.</p></li><li class="li"><p>Designate an audio player delegate object, which handles interruptions as well as the playback-completed event.</p></li></ol><p>The code in <span class="content_text">Listing 1-4</span> illustrates these steps. It would typically go into an initialization method of the controller class for your application. (In production code, you’d include appropriate error handling.)</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW22" title="Listing 1-4Configuring an AVAudioPlayer object"></a><p class="codesample clear"><strong class="caption_number">Listing 1-4</strong>&nbsp;&nbsp;Configuring an AVAudioPlayer object</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>// in the corresponding .h file:<span></span></pre></td></tr><tr><td scope="row"><pre>// @property (nonatomic, retain) AVAudioPlayer *player;<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>// in the .m file:<span></span></pre></td></tr><tr><td scope="row"><pre>@synthesize player; // the player object<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>NSString *soundFilePath =<span></span></pre></td></tr><tr><td scope="row"><pre>            [[NSBundle mainBundle] pathForResource: @"sound"<span></span></pre></td></tr><tr><td scope="row"><pre>                                            ofType: @"wav"];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>NSURL *fileURL = [[NSURL alloc] initFileURLWithPath: soundFilePath];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>AVAudioPlayer *newPlayer =<span></span></pre></td></tr><tr><td scope="row"><pre>            [[AVAudioPlayer alloc] initWithContentsOfURL: fileURL<span></span></pre></td></tr><tr><td scope="row"><pre>                                                   error: nil];<span></span></pre></td></tr><tr><td scope="row"><pre>[fileURL release];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>self.player = newPlayer;<span></span></pre></td></tr><tr><td scope="row"><pre>[newPlayer release];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>[player prepareToPlay];<span></span></pre></td></tr><tr><td scope="row"><pre>[player setDelegate: self];<span></span></pre></td></tr></tbody></table></div><p>The <span class="pediaLink" data-header="Delegation" data-contents="Delegation is a simple and powerful pattern in which one object in a program acts on behalf of, or in coordination with, another object. "><a data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/General/Conceptual/DevPedia-CocoaCore/D_1&quot;;return this.s_oc?this.s_oc(e):true" data-href="../../../../General/Conceptual/DevPedia-CocoaCore/Delegation.html#//apple_ref/doc/uid/TP40008195-CH14">delegate</a></span> (which can be your <span class="pediaLink" data-header="Controller object" data-contents="A controller object acts as a coordinator or as an intermediary between one or more view objects and one or more model objects. "><a data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/General/Conceptual/DevPedia-CocoaCore/C_1&quot;;return this.s_oc?this.s_oc(e):true" data-href="../../../../General/Conceptual/DevPedia-CocoaCore/ControllerObject.html#//apple_ref/doc/uid/TP40008195-CH11">controller object</a></span>) handles interruptions and updates the user interface when a sound has finished playing. The delegate methods for the <code>AVAudioPlayer</code> class are described in <em><a href="https://developer.apple.com/documentation/avfoundation/avaudioplayerdelegate" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudioplayerdelegate_1&quot;;return this.s_oc?this.s_oc(e):true">AVAudioPlayerDelegate Protocol Reference</a></em>. <span class="content_text">Listing 1-5</span> shows a simple implementation of one delegate method. This code updates the title of a Play/Pause toggle button when a sound has finished playing.</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW23" title="Listing 1-5Implementing an AVAudioPlayer delegate method"></a><p class="codesample clear"><strong class="caption_number">Listing 1-5</strong>&nbsp;&nbsp;Implementing an AVAudioPlayer delegate method</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>- (void) audioPlayerDidFinishPlaying: (AVAudioPlayer *) player<span></span></pre></td></tr><tr><td scope="row"><pre>                        successfully: (BOOL) completed {<span></span></pre></td></tr><tr><td scope="row"><pre>    if (completed == YES) {<span></span></pre></td></tr><tr><td scope="row"><pre>        [self.button setTitle: @"Play" forState: UIControlStateNormal];<span></span></pre></td></tr><tr><td scope="row"><pre>    }<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></tbody></table></div><p>To play, pause, or stop an <code>AVAudioPlayer</code> object, call one of its playback control methods. You can test whether or not playback is in progress by using the <code>playing</code> property. <span class="content_text">Listing 1-6</span> shows a basic play/pause toggle method that controls playback and updates the title of a <code>UIButton</code> object.</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW21" title="Listing 1-6Controlling an AVAudioPlayer object"></a><p class="codesample clear"><strong class="caption_number">Listing 1-6</strong>&nbsp;&nbsp;Controlling an AVAudioPlayer object</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>- (IBAction) playOrPause: (id) sender {<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    // if already playing, then pause<span></span></pre></td></tr><tr><td scope="row"><pre>    if (self.player.playing) {<span></span></pre></td></tr><tr><td scope="row"><pre>        [self.button setTitle: @"Play" forState: UIControlStateHighlighted];<span></span></pre></td></tr><tr><td scope="row"><pre>        [self.button setTitle: @"Play" forState: UIControlStateNormal];<span></span></pre></td></tr><tr><td scope="row"><pre>        [self.player pause];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    // if stopped or paused, start playing<span></span></pre></td></tr><tr><td scope="row"><pre>    } else {<span></span></pre></td></tr><tr><td scope="row"><pre>        [self.button setTitle: @"Pause" forState: UIControlStateHighlighted];<span></span></pre></td></tr><tr><td scope="row"><pre>        [self.button setTitle: @"Pause" forState: UIControlStateNormal];<span></span></pre></td></tr><tr><td scope="row"><pre>        [self.player play];<span></span></pre></td></tr><tr><td scope="row"><pre>    }<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></tbody></table></div><p>The <code>AVAudioPlayer</code> class uses the Objective-C <span class="pediaLink" data-header="Declared property" data-contents="A declared property provides a syntactical shorthand for declaring a class’s accessor methods and, optionally, implementing them. "><a data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/General/Conceptual/DevPedia-CocoaCore/D_2&quot;;return this.s_oc?this.s_oc(e):true" data-href="../../../../General/Conceptual/DevPedia-CocoaCore/DeclaredProperty.html#//apple_ref/doc/uid/TP40008195-CH13">declared properties</a></span> feature for managing information about a sound—such as the playback point within the sound’s timeline, and for accessing playback options—such as volume and looping. For example, you can set the playback volume for an audio player as shown here:</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>[self.player setVolume: 1.0];    // available range is 0.0 through 1.0<span></span></pre></td></tr></tbody></table></div><p>For more information on the <code>AVAudioPlayer</code> class, see <em><a href="https://developer.apple.com/documentation/avfoundation/avaudioplayer" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudioplayer_2&quot;;return this.s_oc?this.s_oc(e):true">AVAudioPlayer Class Reference</a></em>.</p></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW5" title="Playing Sounds with Control Using Audio Queue Services"></a><h3 class="jump">Playing Sounds with Control Using Audio Queue Services</h3><p>Audio Queue Services adds playback capabilities beyond those available with the <code>AVAudioPlayer</code> class. Using Audio Queue Services for playback lets you:</p><ul class="ul"><li class="li"><p>Precisely schedule when a sound plays, allowing synchronization</p></li><li class="li"><p>Precisely control volume on a buffer-by-buffer basis</p></li><li class="li"><p>Play audio that you have captured from a stream using Audio File Stream Services</p></li></ul><p>Audio Queue Services lets you play sound in any audio format available in iOS, as described in <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW48" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_15&quot;;return this.s_oc?this.s_oc(e):true">Table 1-1</a></span>. You can also use this technology for recording, as explained in <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW7" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_16&quot;;return this.s_oc?this.s_oc(e):true">Recording Audio</a></span>.</p><p>For detailed information on using this technology, see <em><a href="https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioQueueProgrammingGuide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40005343" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioQueueProgram_2&quot;;return this.s_oc?this.s_oc(e):true">Audio Queue Services Programming Guide</a></em> and <em><a href="https://developer.apple.com/documentation/audiotoolbox/audio_queue_services" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/audio_queue_services_1&quot;;return this.s_oc?this.s_oc(e):true">Audio Queue Services Reference</a></em>. For sample code, see the <em><!--a target="_self" -->SpeakHere<!--/a--></em> sample. </p><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW38" title="Creating an Audio Queue Object"></a><h4 class="jump">Creating an Audio Queue Object</h4><p>To create an audio queue object for playback, perform these three steps:</p><ol class="ol"><li class="li"><p>Create a data structure to manage information needed by the audio queue, such as the audio format for the data you want to play.</p></li><li class="li"><p>Define a callback function for managing audio queue buffers. The callback uses Audio File Services to read the file you want to play. (In iOS 2.1 and later, you can also use Extended Audio File Services to read the file.)</p></li><li class="li"><p>Instantiate the playback audio queue using the <code><a href="https://developer.apple.com/documentation/audiotoolbox/1503207-audioqueuenewoutput" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/1503207-audioqueuenewoutput_1&quot;;return this.s_oc?this.s_oc(e):true">AudioQueueNewOutput</a></code> function.</p></li></ol><p><span class="content_text">Listing 1-7</span> illustrates these steps using ANSI C. (In production code, you’d include appropriate error handling.) The <em><!--a target="_self" -->SpeakHere<!--/a--></em> sample project shows these same steps in the context of a C++ program.</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW25" title="Listing 1-7Creating an audio queue object"></a><p class="codesample clear"><strong class="caption_number">Listing 1-7</strong>&nbsp;&nbsp;Creating an audio queue object</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>static const int kNumberBuffers = 3;<span></span></pre></td></tr><tr><td scope="row"><pre>// Create a data structure to manage information needed by the audio queue<span></span></pre></td></tr><tr><td scope="row"><pre>struct myAQStruct {<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioFileID                     mAudioFile;<span></span></pre></td></tr><tr><td scope="row"><pre>    CAStreamBasicDescription        mDataFormat;<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueRef                   mQueue;<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueBufferRef             mBuffers[kNumberBuffers];<span></span></pre></td></tr><tr><td scope="row"><pre>    SInt64                          mCurrentPacket;<span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32                          mNumPacketsToRead;<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioStreamPacketDescription    *mPacketDescs;<span></span></pre></td></tr><tr><td scope="row"><pre>    bool                            mDone;<span></span></pre></td></tr><tr><td scope="row"><pre>};<span></span></pre></td></tr><tr><td scope="row"><pre>// Define a playback audio queue callback function<span></span></pre></td></tr><tr><td scope="row"><pre>static void AQTestBufferCallback(<span></span></pre></td></tr><tr><td scope="row"><pre>    void                   *inUserData,<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueRef          inAQ,<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueBufferRef    inCompleteAQBuffer<span></span></pre></td></tr><tr><td scope="row"><pre>) {<span></span></pre></td></tr><tr><td scope="row"><pre>    myAQStruct *myInfo = (myAQStruct *)inUserData;<span></span></pre></td></tr><tr><td scope="row"><pre>    if (myInfo-&gt;mDone) return;<span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32 numBytes;<span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32 nPackets = myInfo-&gt;mNumPacketsToRead;<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    AudioFileReadPackets (<span></span></pre></td></tr><tr><td scope="row"><pre>        myInfo-&gt;mAudioFile,<span></span></pre></td></tr><tr><td scope="row"><pre>        false,<span></span></pre></td></tr><tr><td scope="row"><pre>        &amp;numBytes,<span></span></pre></td></tr><tr><td scope="row"><pre>        myInfo-&gt;mPacketDescs,<span></span></pre></td></tr><tr><td scope="row"><pre>        myInfo-&gt;mCurrentPacket,<span></span></pre></td></tr><tr><td scope="row"><pre>        &amp;nPackets,<span></span></pre></td></tr><tr><td scope="row"><pre>        inCompleteAQBuffer-&gt;mAudioData<span></span></pre></td></tr><tr><td scope="row"><pre>    );<span></span></pre></td></tr><tr><td scope="row"><pre>    if (nPackets &gt; 0) {<span></span></pre></td></tr><tr><td scope="row"><pre>        inCompleteAQBuffer-&gt;mAudioDataByteSize = numBytes;<span></span></pre></td></tr><tr><td scope="row"><pre>        AudioQueueEnqueueBuffer (<span></span></pre></td></tr><tr><td scope="row"><pre>            inAQ,<span></span></pre></td></tr><tr><td scope="row"><pre>            inCompleteAQBuffer,<span></span></pre></td></tr><tr><td scope="row"><pre>            (myInfo-&gt;mPacketDescs ? nPackets : 0),<span></span></pre></td></tr><tr><td scope="row"><pre>            myInfo-&gt;mPacketDescs<span></span></pre></td></tr><tr><td scope="row"><pre>        );<span></span></pre></td></tr><tr><td scope="row"><pre>        myInfo-&gt;mCurrentPacket += nPackets;<span></span></pre></td></tr><tr><td scope="row"><pre>    } else {<span></span></pre></td></tr><tr><td scope="row"><pre>        AudioQueueStop (<span></span></pre></td></tr><tr><td scope="row"><pre>            myInfo-&gt;mQueue,<span></span></pre></td></tr><tr><td scope="row"><pre>            false<span></span></pre></td></tr><tr><td scope="row"><pre>        );<span></span></pre></td></tr><tr><td scope="row"><pre>        myInfo-&gt;mDone = true;<span></span></pre></td></tr><tr><td scope="row"><pre>    }<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr><tr><td scope="row"><pre>// Instantiate an audio queue object<span></span></pre></td></tr><tr><td scope="row"><pre>AudioQueueNewOutput (<span></span></pre></td></tr><tr><td scope="row"><pre>    &amp;myInfo.mDataFormat,<span></span></pre></td></tr><tr><td scope="row"><pre>    AQTestBufferCallback,<span></span></pre></td></tr><tr><td scope="row"><pre>    &amp;myInfo,<span></span></pre></td></tr><tr><td scope="row"><pre>    CFRunLoopGetCurrent(),<span></span></pre></td></tr><tr><td scope="row"><pre>    kCFRunLoopCommonModes,<span></span></pre></td></tr><tr><td scope="row"><pre>    0,<span></span></pre></td></tr><tr><td scope="row"><pre>    &amp;myInfo.mQueue<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr></tbody></table></div></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW39" title="Controlling the Playback Level"></a><h4 class="jump">Controlling the Playback Level</h4><p>Audio queue objects give you two ways to control playback level.</p><p>To set playback level directly, use the <code><a href="https://developer.apple.com/documentation/audiotoolbox/1503293-audioqueuesetparameter" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/1503293-audioqueuesetparameter_1&quot;;return this.s_oc?this.s_oc(e):true">AudioQueueSetParameter</a></code> function with the <code>kAudioQueueParam_Volume</code> parameter, as shown in <span class="content_text">Listing 1-8</span>. Level change takes effect immediately.</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW26" title="Listing 1-8Setting the playback level directly"></a><p class="codesample clear"><strong class="caption_number">Listing 1-8</strong>&nbsp;&nbsp;Setting the playback level directly</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>Float32 volume = 1;    // linear scale, range from 0.0 through 1.0<span></span></pre></td></tr><tr><td scope="row"><pre>AudioQueueSetParameter (<span></span></pre></td></tr><tr><td scope="row"><pre>    myAQstruct.audioQueueObject,<span></span></pre></td></tr><tr><td scope="row"><pre>    kAudioQueueParam_Volume,<span></span></pre></td></tr><tr><td scope="row"><pre>    volume<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr></tbody></table></div><p>You can also set playback level for an audio queue buffer by using the <code><a href="https://developer.apple.com/documentation/audiotoolbox/1503258-audioqueueenqueuebufferwithparam" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/1503258-audioqueueenqueuebufferwithparam_1&quot;;return this.s_oc?this.s_oc(e):true">AudioQueueEnqueueBufferWithParameters</a></code> function. This lets you assign audio queue settings that are, in effect, carried by an audio queue buffer as you enqueue it. Such changes take effect when the buffer begins playing.</p><p>In both cases, level changes for an audio queue remain in effect until you change them again.</p></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW29" title="Indicating Playback Level"></a><h4 class="jump">Indicating Playback Level</h4><p>You can obtain the current playback level from an audio queue object by:</p><ol class="ol"><li class="li"><p>Enabling metering for the audio queue object by setting its <code>kAudioQueueProperty_EnableLevelMetering</code> property to <code>true</code></p></li><li class="li"><p>Querying the audio queue object’s <code>kAudioQueueProperty_CurrentLevelMeter</code> property</p></li></ol><p>The value of this property is an array of <code>AudioQueueLevelMeterState</code> structures, one per channel. <span class="content_text">Listing 1-9</span> shows this structure:</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW27" title="Listing 1-9The AudioQueueLevelMeterState structure"></a><p class="codesample clear"><strong class="caption_number">Listing 1-9</strong>&nbsp;&nbsp;The <code>AudioQueueLevelMeterState</code> structure</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>typedef struct AudioQueueLevelMeterState {<span></span></pre></td></tr><tr><td scope="row"><pre>    Float32     mAveragePower;<span></span></pre></td></tr><tr><td scope="row"><pre>    Float32     mPeakPower;<span></span></pre></td></tr><tr><td scope="row"><pre>};  AudioQueueLevelMeterState;<span></span></pre></td></tr></tbody></table></div></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW40" title="Playing Multiple Sounds Simultaneously"></a><h4 class="jump">Playing Multiple Sounds Simultaneously</h4><p>To play multiple sounds simultaneously, create one playback audio queue object for each sound. For each audio queue, schedule the first buffer of audio to start at the same time using the <code><a href="https://developer.apple.com/documentation/audiotoolbox/1503258-audioqueueenqueuebufferwithparam" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/1503258-audioqueueenqueuebufferwithparam_2&quot;;return this.s_oc?this.s_oc(e):true">AudioQueueEnqueueBufferWithParameters</a></code> function.</p><p>Starting in iOS 3.0, nearly all supported audio formats can be used for simultaneous playback—namely, all those that can be played using software decoding, as described in <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW48" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_17&quot;;return this.s_oc?this.s_oc(e):true">Table 1-1</a></span>. For the most processor-efficient multiple playback, use linear PCM (uncompressed) or IMA4 (compressed) audio.</p></section></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW3" title="Playing Sounds with Positioning Using OpenAL"></a><h3 class="jump">Playing Sounds with Positioning Using OpenAL</h3><p>The open-sourced OpenAL audio API, available in iOS in the OpenAL <span class="pediaLink" data-header="Framework" data-contents="A framework is a bundle (a structured directory) that contains a dynamic shared library along with associated resources, such as nib files, image files, and header files. "><a data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/General/Conceptual/DevPedia-CocoaCore/F_2&quot;;return this.s_oc?this.s_oc(e):true" data-href="../../../../General/Conceptual/DevPedia-CocoaCore/Framework.html#//apple_ref/doc/uid/TP40008195-CH56">framework</a></span>, provides an interface optimized for positioning sounds in a stereo field during playback. Playing, positioning, and moving sounds works just as it does on other platforms. OpenAL also lets you mix sounds. OpenAL uses the I/O unit for playback, resulting in the lowest latency.</p><p>For all of these reasons, OpenAL is your best choice for playing sounds in game applications on iOS-based devices. However, OpenAL is also a good choice for general iOS application audio playback needs.</p><p>OpenAL 1.1 support in iOS is built on top of Core Audio. For more information, see <em><a href="https://developer.apple.com/library/archive/technotes/tn2199/_index.html#//apple_ref/doc/uid/DTS40007999" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/technotes/tn2199/_index.html#//apple_ref/doc/uid/DTS4_2&quot;;return this.s_oc?this.s_oc(e):true">OpenAL FAQ for iPhone OS</a></em>. For sample code, see <em><!--a target="_self" -->oalTouch<!--/a--></em>. </p></section></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW7" title="Recording Audio"></a><h2 class="jump">Recording Audio</h2><p>iOS supports audio recording using the <code><a href="https://developer.apple.com/documentation/avfoundation/avaudiorecorder" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudiorecorder_1&quot;;return this.s_oc?this.s_oc(e):true">AVAudioRecorder</a></code> class and Audio Queue Services. These interfaces do the work of connecting to the audio hardware, managing memory, and employing codecs as needed. You can record audio in any of the formats listed in <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW49" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_18&quot;;return this.s_oc?this.s_oc(e):true">Table 1-2</a></span>.</p><p>Recording takes place at a system-defined input level in iOS. The system takes input from the audio source that the user has chosen—the built-in microphone or, if connected, the headset microphone or other input source.</p><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW14" title="Recording with the AVAudioRecorder Class"></a><h3 class="jump">Recording with the AVAudioRecorder Class</h3><p>The easiest way to record sound in iOS is with the <code>AVAudioRecorder</code> class, described in <em><a href="https://developer.apple.com/documentation/avfoundation/avaudiorecorder" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudiorecorder_2&quot;;return this.s_oc?this.s_oc(e):true">AVAudioRecorder Class Reference</a></em>. This class provides a highly-streamlined, Objective-C interface that makes it easy to provide sophisticated features like pausing/resuming recording and handling audio interruptions. At the same time, you retain complete control over recording format.</p><p>To prepare for recording using an audio recorder:</p><ol class="ol"><li class="li"><p>Specify a sound file URL.</p></li><li class="li"><p>Set up the audio session.</p></li><li class="li"><p>Configure the audio recorder’s initial state.</p></li></ol><p>Application launch is a good time to do this part of the setup, as shown in <span class="content_text">Listing 1-10</span>. Variables such as <code>soundFileURL</code> and <code>recording</code> in this example are declared in the class interface. (In production code, you would include appropriate error handling.)</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW42" title="Listing 1-10Setting up the audio session and the sound file URL"></a><p class="codesample clear"><strong class="caption_number">Listing 1-10</strong>&nbsp;&nbsp;Setting up the audio session and the sound file URL</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>- (void) viewDidLoad {<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    [super viewDidLoad];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    NSString *tempDir = NSTemporaryDirectory ();<span></span></pre></td></tr><tr><td scope="row"><pre>    NSString *soundFilePath =<span></span></pre></td></tr><tr><td scope="row"><pre>                [tempDir stringByAppendingString: @"sound.caf"];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    NSURL *newURL = [[NSURL alloc] initFileURLWithPath: soundFilePath];<span></span></pre></td></tr><tr><td scope="row"><pre>    self.soundFileURL = newURL;<span></span></pre></td></tr><tr><td scope="row"><pre>    [newURL release];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    AVAudioSession *audioSession = [AVAudioSession sharedInstance];<span></span></pre></td></tr><tr><td scope="row"><pre>    audioSession.delegate = self;<span></span></pre></td></tr><tr><td scope="row"><pre>    [audioSession setActive: YES error: nil];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    recording = NO;<span></span></pre></td></tr><tr><td scope="row"><pre>    playing = NO;<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></tbody></table></div><p>To handle interruptions and the completion of recording, add the <code><a href="https://developer.apple.com/documentation/avfoundation/avaudiosessiondelegate" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudiosessiondelegate_2&quot;;return this.s_oc?this.s_oc(e):true">AVAudioSessionDelegate</a></code> and <code><a href="https://developer.apple.com/documentation/avfoundation/avaudiorecorderdelegate" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudiorecorderdelegate_1&quot;;return this.s_oc?this.s_oc(e):true">AVAudioRecorderDelegate</a></code> protocol names to the interface declaration for your implementation. If your application also does playback, also adopt the <code><a href="https://developer.apple.com/documentation/avfoundation/avaudioplayerdelegate" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudioplayerdelegate_2&quot;;return this.s_oc?this.s_oc(e):true">AVAudioPlayerDelegate Protocol Reference</a></code> protocol.</p><p>To implement a record method, you can use code such as that shown in <span class="content_text">Listing 1-11</span>. (In production code, you would include appropriate error handling.)</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW44" title="Listing 1-11A record/stop method using the AVAudioRecorder class"></a><p class="codesample clear"><strong class="caption_number">Listing 1-11</strong>&nbsp;&nbsp;A record/stop method using the AVAudioRecorder class</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>- (IBAction) recordOrStop: (id) sender {<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>   if (recording) {<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>      [soundRecorder stop];<span></span></pre></td></tr><tr><td scope="row"><pre>      recording = NO;<span></span></pre></td></tr><tr><td scope="row"><pre>      self.soundRecorder = nil;<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>      [recordOrStopButton setTitle: @"Record" forState:<span></span></pre></td></tr><tr><td scope="row"><pre>                                        UIControlStateNormal];<span></span></pre></td></tr><tr><td scope="row"><pre>      [recordOrStopButton setTitle: @"Record" forState:<span></span></pre></td></tr><tr><td scope="row"><pre>                                        UIControlStateHighlighted];<span></span></pre></td></tr><tr><td scope="row"><pre>      [[AVAudioSession sharedInstance] setActive: NO error: nil];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>   } else {<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>      [[AVAudioSession sharedInstance]<span></span></pre></td></tr><tr><td scope="row"><pre>                            setCategory: AVAudioSessionCategoryRecord<span></span></pre></td></tr><tr><td scope="row"><pre>                                  error: nil];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>      NSDictionary *recordSettings =<span></span></pre></td></tr><tr><td scope="row"><pre>         [[NSDictionary alloc] initWithObjectsAndKeys:<span></span></pre></td></tr><tr><td scope="row"><pre>           [NSNumber numberWithFloat: 44100.0], AVSampleRateKey,<span></span></pre></td></tr><tr><td scope="row"><pre>             [NSNumber numberWithInt: kAudioFormatAppleLossless], AVFormatIDKey,<span></span></pre></td></tr><tr><td scope="row"><pre>             [NSNumber numberWithInt: 1], AVNumberOfChannelsKey,<span></span></pre></td></tr><tr><td scope="row"><pre>             [NSNumber numberWithInt: AVAudioQualityMax],<span></span></pre></td></tr><tr><td scope="row"><pre>                                        AVEncoderAudioQualityKey,<span></span></pre></td></tr><tr><td scope="row"><pre>             nil];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>      AVAudioRecorder *newRecorder =<span></span></pre></td></tr><tr><td scope="row"><pre>            [[AVAudioRecorder alloc] initWithURL: soundFileURL<span></span></pre></td></tr><tr><td scope="row"><pre>                                        settings: recordSettings<span></span></pre></td></tr><tr><td scope="row"><pre>                                           error: nil];<span></span></pre></td></tr><tr><td scope="row"><pre>      [recordSettings release];<span></span></pre></td></tr><tr><td scope="row"><pre>      self.soundRecorder = newRecorder;<span></span></pre></td></tr><tr><td scope="row"><pre>      [newRecorder release];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>      soundRecorder.delegate = self;<span></span></pre></td></tr><tr><td scope="row"><pre>      [soundRecorder prepareToRecord];<span></span></pre></td></tr><tr><td scope="row"><pre>      [soundRecorder record];<span></span></pre></td></tr><tr><td scope="row"><pre>      [recordOrStopButton setTitle: @"Stop" forState: UIControlStateNormal];<span></span></pre></td></tr><tr><td scope="row"><pre>      [recordOrStopButton setTitle: @"Stop" forState: UIControlStateHighlighted];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>      recording = YES;<span></span></pre></td></tr><tr><td scope="row"><pre>   }<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></tbody></table></div><p>For more information on the <code>AVAudioRecorder</code> class, see <em><a href="https://developer.apple.com/documentation/avfoundation/avaudiorecorder" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/avfoundation/avaudiorecorder_3&quot;;return this.s_oc?this.s_oc(e):true">AVAudioRecorder Class Reference</a></em>.</p></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW16" title="Recording with Audio Queue Services"></a><h3 class="jump">Recording with Audio Queue Services</h3><p>To set up for recording with audio with Audio Queue Services, your application instantiates a recording audio queue object and provides a callback function. The callback stores incoming audio data in memory for immediate use or writes it to a file for long-term storage.</p><p>Just as with playback, you can obtain the current recording audio level from an audio queue object by querying its <code>kAudioQueueProperty_CurrentLevelMeter</code> property, as described in <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW29" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_19&quot;;return this.s_oc?this.s_oc(e):true">Indicating Playback Level</a></span>.</p><p>For detailed examples of how to use Audio Queue Services to record audio, see <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioQueueProgrammingGuide/AQRecord/RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioQueueProgram_3&quot;;return this.s_oc?this.s_oc(e):true">Recording Audio</a></span> in <em><a href="https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioQueueProgrammingGuide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40005343" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioQueueProgram_4&quot;;return this.s_oc?this.s_oc(e):true">Audio Queue Services Programming Guide</a></em>. For sample code, see the <em><!--a target="_self" -->SpeakHere<!--/a--></em> sample.</p></section></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW8" title="Parsing Streamed Audio"></a><h2 class="jump">Parsing Streamed Audio</h2><p>To play streamed audio content, such as from a network connection, use Audio File Stream Services in concert with Audio Queue Services. Audio File Stream Services parses audio packets and metadata from common audio file container formats in a network bitstream. You can also use it to parse packets and metadata from on-disk files.</p><p>In iOS, you can parse the same audio file and bitstream formats that you can in Mac OS X, as follows:</p><ul class="ul"><li class="li"><p>MPEG-1 Audio Layer 3, used for .mp3 files</p></li><li class="li"><p>MPEG-2 ADTS, used for the .aac audio data format</p></li><li class="li"><p>AIFC</p></li><li class="li"><p>AIFF</p></li><li class="li"><p>CAF</p></li><li class="li"><p>MPEG-4, used for .m4a, .mp4, and .3gp files</p></li><li class="li"><p>NeXT</p></li><li class="li"><p>WAVE</p></li></ul><p>Having retrieved audio packets, you can play back the recovered sound in any of the formats supported in iOS, as listed in <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW48" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_20&quot;;return this.s_oc?this.s_oc(e):true">Table 1-1</a></span>.</p><p>For best performance, network streaming applications should use data from Wi-Fi connections. iOS lets you determine which networks are reachable and available through its System Configuration <span class="pediaLink" data-header="Framework" data-contents="A framework is a bundle (a structured directory) that contains a dynamic shared library along with associated resources, such as nib files, image files, and header files. "><a data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/General/Conceptual/DevPedia-CocoaCore/F_3&quot;;return this.s_oc?this.s_oc(e):true" data-href="../../../../General/Conceptual/DevPedia-CocoaCore/Framework.html#//apple_ref/doc/uid/TP40008195-CH56">framework</a></span> and its <code><a href="https://developer.apple.com/documentation/systemconfiguration/scnetworkreachability" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/systemconfiguration/scnetworkreachability_1&quot;;return this.s_oc?this.s_oc(e):true">SCNetworkReachabilityRef</a></code> opaque type, described in <em><a href="https://developer.apple.com/documentation/systemconfiguration/scnetworkreachability" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/systemconfiguration/scnetworkreachability_2&quot;;return this.s_oc?this.s_oc(e):true">SCNetworkReachability Reference</a></em>. For sample code, see the <em><a href="https://developer.apple.com/library/archive/samplecode/Reachability/Introduction/Intro.html#//apple_ref/doc/uid/DTS40007324" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/samplecode/Reachability/Introduction/Intro.html#//app_1&quot;;return this.s_oc?this.s_oc(e):true">Reachability</a></em> sample in the <span class="content_text"><a href="http://developer.apple.com/iphone/" class="browserLink" onclick="s_objectID=&quot;http://developer.apple.com/iphone/_3&quot;;return this.s_oc?this.s_oc(e):true">iOS Dev Center</a></span>.</p><p>To connect to a network stream, use interfaces from Core Foundation, such as the one described in <em><!--a target="_self" -->CFHTTPMessage Reference<!--/a--></em>. Parse the network packets to recover audio packets using Audio File Stream Services. Then buffer the audio packets and send them to a playback audio queue object.</p><p>Audio File Stream Services relies on interfaces from Audio File Services, such as the <code><a href="https://developer.apple.com/documentation/audiotoolbox/audioframepackettranslation" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/audioframepackettranslation_1&quot;;return this.s_oc?this.s_oc(e):true">AudioFramePacketTranslation</a></code> structure and the <code><a href="https://developer.apple.com/documentation/audiotoolbox/audiofilepackettableinfo" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/audiofilepackettableinfo_1&quot;;return this.s_oc?this.s_oc(e):true">AudioFilePacketTableInfo</a></code> structure. These are described in <em><a href="https://developer.apple.com/documentation/audiotoolbox/audio_file_services" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/audio_file_services_1&quot;;return this.s_oc?this.s_oc(e):true">Audio File Services Reference</a></em>.</p><p>For more information on using streams, refer to <em><a href="https://developer.apple.com/documentation/audiotoolbox/audio_file_stream_services" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/audio_file_stream_services_1&quot;;return this.s_oc?this.s_oc(e):true">Audio File Stream Services Reference</a></em>. </p></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW4" title="Audio Unit Support in iOS"></a><h2 class="jump">Audio Unit Support in iOS</h2><p>iOS provides a set of audio processing plug-ins, known as <em>audio units</em>, that you can use in any application. The interfaces in the Audio Unit <span class="pediaLink" data-header="Framework" data-contents="A framework is a bundle (a structured directory) that contains a dynamic shared library along with associated resources, such as nib files, image files, and header files. "><a data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/General/Conceptual/DevPedia-CocoaCore/F_4&quot;;return this.s_oc?this.s_oc(e):true" data-href="../../../../General/Conceptual/DevPedia-CocoaCore/Framework.html#//apple_ref/doc/uid/TP40008195-CH56">framework</a></span> let you open, connect, and use these audio units. </p><p>To use the features of the Audio Unit framework, add the <em>Audio Toolbox</em> framework to your Xcode project and link against it in any relevant targets. Then add a <code>#import &lt;AudioToolbox/AudioToolbox.h&gt;</code> statement near the top of relevant source files. For detailed information on how to add frameworks to your project, see <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/XcodeProjectManagement/130-Files_in_Projects/project_files.html#//apple_ref/doc/uid/TP40002666" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/XcodeProjectM_3&quot;;return this.s_oc?this.s_oc(e):true">Files in Projects</a></span> in <em><a href="https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/XcodeProjectManagement/000-Introduction/introduction.html#//apple_ref/doc/uid/TP40006917" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/XcodeProjectM_4&quot;;return this.s_oc?this.s_oc(e):true">Xcode Project Management Guide</a></em>.</p><p><span class="content_text">Table 1-5</span> lists the audio units provided in iOS.</p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW30" title="Table 1-5System-supplied audio units"></a><div class="tableholder"><table class="graybox" border="0" cellspacing="0" cellpadding="5"><caption class="tablecaption"><strong class="caption_number">Table 1-5</strong>&nbsp;&nbsp;System-supplied audio units</caption><tbody><tr><th scope="col" class="TableHeading_TableRow_TableCell"><p>Audio unit</p></th><th scope="col" class="TableHeading_TableRow_TableCell"><p>Description</p></th></tr><tr><td scope="row"><p><em class="newTerm">iPod Equalizer unit</em></p></td><td><p>The iPod EQ unit, of type <code>kAudioUnitSubType_AUiPodEQ</code>, provides a simple, preset-based equalizer you can use in your application. For a demonstration of how to use this audio unit, see the sample code project <em><a href="https://developer.apple.com/library/archive/samplecode/iPhoneMixerEQGraphTest/Introduction/Intro.html#//apple_ref/doc/uid/DTS40009555" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/samplecode/iPhoneMixerEQGraphTest/Introduction/Intro._1&quot;;return this.s_oc?this.s_oc(e):true">Mixer iPodEQ AUGraph Test</a></em>.</p></td></tr><tr><td scope="row"><p><em class="newTerm">3D Mixer unit</em></p></td><td><p>The 3D Mixer unit, of type <code>kAudioUnitSubType_AU3DMixerEmbedded</code>, lets you mix multiple audio streams, specify stereo output panning, manipulate playback rate, and more. OpenAL is built on top of this audio unit and provides a higher-level API well suited for game apps.</p></td></tr><tr><td scope="row"><p><em class="newTerm">Multichannel&nbsp;Mixer&nbsp;unit</em></p></td><td><p>The Multichannel Mixer unit, of type <code>kAudioUnitSubType_MultiChannelMixer</code>, lets you mix multiple mono or stereo audio streams to a single stereo stream. It also supports left/right panning for each input. For a demonstration of how to use this audio unit, see the sample code project <em><!--a target="_self" -->Audio Mixer (MixerHost)<!--/a--></em>.</p></td></tr><tr><td scope="row"><p><em class="newTerm">Remote&nbsp;I/O&nbsp;unit</em></p></td><td><p>The Remote I/O unit, of type <code>kAudioUnitSubType_RemoteIO</code>, connects to audio input and output hardware and supports realtime I/O. For demonstrations of how to use this audio unit, see the sample code project <em><a href="https://developer.apple.com/library/archive/samplecode/aurioTouch/Introduction/Intro.html#//apple_ref/doc/uid/DTS40007770" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/samplecode/aurioTouch/Introduction/Intro.html#//apple_1&quot;;return this.s_oc?this.s_oc(e):true">aurioTouch</a></em>.</p></td></tr><tr><td scope="row"><p><em class="newTerm">Voice&nbsp;Processing&nbsp;I/O&nbsp;unit</em></p></td><td><p>The Voice Processing I/O unit, of type <code>kAudioUnitSubType_VoiceProcessingIO</code>, has the characteristics of the I/O unit and adds echo suppression and other features for two-way communication.</p></td></tr><tr><td scope="row"><p><em class="newTerm">Generic&nbsp;Output&nbsp;unit</em></p></td><td><p>The Generic Output unit, of type <code>kAudioUnitSubType_GenericOutput</code>, supports converting to and from linear PCM format; can be used to start and stop a graph.</p></td></tr><tr><td scope="row"><p><em class="newTerm">Converter unit</em></p></td><td><p>The Converter unit, of type <code>kAudioUnitSubType_AUConverter</code>, lets you convert audio data from one format to another. You typically obtain the features of this audio unit by using the Remote I/O unit, which incorporates a Converter unit.</p></td></tr></tbody></table></div><p>For more information on using system audio units, see <em><a href="https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioUnitHostingGuide_iOS/Introduction/Introduction.html#//apple_ref/doc/uid/TP40009492" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/AudioUnitHostingG_3&quot;;return this.s_oc?this.s_oc(e):true">Audio Unit Hosting Guide for iOS</a></em>. For reference documentation, see <em><a href="https://developer.apple.com/documentation/audiounit" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiounit_1&quot;;return this.s_oc?this.s_oc(e):true">Audio Unit Framework Reference</a></em> and <em><a href="https://developer.apple.com/documentation/audiotoolbox/audio_unit_processing_graph_services" class="urlLink" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/documentation/audiotoolbox/audio_unit_processing_graph_services_1&quot;;return this.s_oc?this.s_oc(e):true">Audio Unit Processing Graph Services Reference</a></em>. The iOS Dev Center provides two sample-code projects that demonstrate use of system audio units: <em><a href="https://developer.apple.com/library/archive/samplecode/aurioTouch/Introduction/Intro.html#//apple_ref/doc/uid/DTS40007770" data-renderer-version="1" target="_self" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/samplecode/aurioTouch/Introduction/Intro.html#//apple_2&quot;;return this.s_oc?this.s_oc(e):true">aurioTouch</a></em> and <em><!--a target="_self" -->iPhoneMultichannelMixerTest<!--/a--></em>.</p></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW10" title="Best Practices for iOS Audio"></a><h2 class="jump">Best Practices for iOS Audio</h2><p>This section lists some important tips for using audio in iOS and describes the best audio data formats for various uses.</p><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW41" title="Tips for Using Audio"></a><h3 class="jump">Tips for Using Audio</h3><p><span class="content_text">Table 1-6</span> lists some important tips to keep in mind when using audio in iOS. </p><a name="//apple_ref/doc/uid/TP40009767-CH2-SW31" title="Table 1-6Audio tips"></a><div class="tableholder"><table class="graybox" border="0" cellspacing="0" cellpadding="5"><caption class="tablecaption"><strong class="caption_number">Table 1-6</strong>&nbsp;&nbsp;Audio tips</caption><tbody><tr><th scope="col" class="TableHeading_TableRow_TableCell"><p>Tip</p></th><th scope="col" class="TableHeading_TableRow_TableCell"><p>Action</p></th></tr><tr><td scope="row"><p>Use&nbsp;compressed&nbsp;audio appropriately</p></td><td><p>For AAC, MP3, and ALAC (Apple Lossless) audio, decoding can take place using hardware-assisted codecs. While efficient, this is limited to one audio stream at a time. If you need to play multiple sounds simultaneously, store those sounds using the IMA4 (compressed) or linear PCM (uncompressed) format.</p></td></tr><tr><td scope="row"><p>Convert to the data format and file format you need</p></td><td><p>The <code>afconvert</code> tool in Mac OS X lets you convert to a wide range of audio data formats and file types. See <span class="content_text"><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingAudio/UsingAudio.html#//apple_ref/doc/uid/TP40009767-CH2-SW28" data-renderer-version="1" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_21&quot;;return this.s_oc?this.s_oc(e):true">Preferred Audio Formats in iOS</a></span> and the <code>afconvert</code> man page.</p></td></tr><tr><td scope="row"><p>Evaluate audio memory issues</p></td><td><p>When playing sound with Audio Queue Services, you write a callback that sends short segments of audio data to audio queue buffers. In some cases, loading an entire sound file to memory for playback, which minimizes disk access, is best. In other cases, loading just enough data at a time to keep the buffers full is best. Test and evaluate which strategy works best for your application.</p></td></tr><tr><td scope="row"><p>Reduce audio file sizes by limiting sample rates, bit depths, and channels</p></td><td><p>Sample rate and the number of bits per sample have a direct impact on the size of your audio files. If you need to play many such sounds, or long-duration sounds, consider reducing these values to reduce the memory footprint of the audio data. For example, rather than use 44.1 kHz sampling rate for sound effects, you could use a 32 kHz (or possibly lower) sample rate and still provide reasonable quality.</p><p>Using monophonic (single-channel) audio instead of stereo (two channel) reduces file size. For each sound asset, consider whether mono could suit your needs.</p></td></tr><tr><td scope="row"><p>Pick the appropriate technology</p></td><td><p>Use OpenAL when you want a convenient, high-level interface for positioning sounds in a stereo field or when you need low latency playback. To parse audio packets from a file or a network stream, use Audio File Stream Services. For simple playback of single or multiple sounds, use the <code>AVAudioPlayer</code> class. For recording to a file, use the <code>AVAudioRecorder</code> class. For audio chat, use the Voice Processing I/O unit. To play audio resources synced from a user’s iTunes library, use iPod Library Access. When your sole audio need is to play alerts and user-interface sound effects, use Core Audio’s System Sound Services. For other audio applications, including playback of streamed audio, precise synchronization, and access to packets of incoming audio, use Audio Queue Services.</p></td></tr><tr><td scope="row"><p>Code for low latency</p></td><td><p>For the lowest possible playback latency, use OpenAL or use the I/O unit directly.</p></td></tr></tbody></table></div></section><section><a name="//apple_ref/doc/uid/TP40009767-CH2-SW28" title="Preferred Audio Formats in iOS"></a><h3 class="jump">Preferred Audio Formats in iOS</h3><p>For uncompressed (highest quality) audio, use 16-bit, little endian, linear PCM audio data packaged in a CAF file. You can convert an audio file to this format in Mac OS X using the <code>afconvert</code> command-line tool, as shown here:</p><div class="codesample clear"><table><tbody><tr><td scope="row"><pre>/usr/bin/afconvert -f caff -d LEI16 {INPUT} {OUTPUT}<span></span></pre></td></tr></tbody></table></div><p>The <code>afconvert</code> tool lets you convert to a wide range of audio data formats and file types. See the <code>afconvert</code> man page, and enter <code>afconvert -h</code> at a shell prompt, for more information.</p><p>For compressed audio when playing one sound at a time, and when you don’t need to play audio simultaneously with the iPod application, use the AAC format packaged in a CAF or m4a file.</p><p>For less memory usage when you need to play multiple sounds simultaneously, use IMA4 (IMA/ADPCM) compression. This reduces file size but entails minimal CPU impact during decompression. As with linear PCM data, package IMA4 data in a CAF file.</p></section></section>
        <div id="pageNavigationLinks_bottom" class="pageNavigationLinks">
            <a class="nextLink" rel="next" href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/UsingVideo/UsingVideo.html" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Usin_22&quot;;return this.s_oc?this.s_oc(e):true">Next</a><a class="previousLink" rel="prev" href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Introduction/Introduction.html" onclick="s_objectID=&quot;https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MultimediaPG/Intr_2&quot;;return this.s_oc?this.s_oc(e):true">Previous</a>
        </div><br>
        <div class="copyright"><br><hr><div align="center"><p class="content_text" lang="en" dir="ltr"> Copyright © 2015 Apple Inc. All Rights Reserved.  <a href="http://www.apple.com/legal/internet-services/terms/site.html" target="_blank" onclick="s_objectID=&quot;http://www.apple.com/legal/internet-services/terms/site.html_1&quot;;return this.s_oc?this.s_oc(e):true">Terms of Use</a>   |  <a href="http://www.apple.com/privacy/" target="_blank" onclick="s_objectID=&quot;http://www.apple.com/privacy/_1&quot;;return this.s_oc?this.s_oc(e):true">Privacy Policy</a>  |  Updated: 2015-03-09</p></div></div>

        <div id="pediaWindow">
            <div id="pediaHeader"></div>
            <div id="pediaBody"></div>
        </div>
    </article>

    
    
    <script charset="utf-8" src="./Multimedia Programming Guide _files/prototype.js"></script>
    <script src="./Multimedia Programming Guide _files/library.js"></script>


</body></html>